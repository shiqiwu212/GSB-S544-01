{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Practice Activity 4.1: Webscraping\"\n",
        "author: \"Shiqi Wu\"\n",
        "format:\n",
        "  html:\n",
        "    self-contained: true\n",
        "jupyter: python3\n",
        "execute:\n",
        "  echo: true\n",
        "---\n",
        "\n",
        "**Repository (Week 4 – Activity 4.1):**  [Week 4](https://github.com/shiqiwu212/GSB-S544-01/tree/2a937d3e40d7ff250b14fa41e7dd0212dae4ef5f/Week%204/Practice%20Activities/Practice%20Activity%204.1)  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrJX4FDa8oA8"
      },
      "source": [
        "# XML, HTML, and Web Scraping\n",
        "\n",
        "JSON and XML are two different ways to represent hierarchical data. Which one is better? There are lots of articles online which discuss similarities and differences between JSON and XML and their advantages and disadvantages. Both formats are still in current usage, so it is good to be familiar with both. However, JSON is more common, so we'll focus on working with JSON representations of hierarchical data.\n",
        "\n",
        "The reading covered an example of using Beautiful Soup to parse XML. Rather than doing another example XML now, we'll skip straight to scraping HTML from a webpage. Both HTML and XML can be parsed in a similar way with Beautiful Soup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XZhT8jhbuZSg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApqnMQ4iV4qu"
      },
      "source": [
        "## Scraping an HTML table with Beautiful Soup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SD7XOs_So3G"
      },
      "source": [
        "Open the URL https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population and scroll down until you see a table of the cities in the U.S. with population over 100,000 (as of Jul 1, 2022). We'll use Beautiful Soup to scrape information from this table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read in the HTML from the ULR using the `requests` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xvYzbSospYVu"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "WIKI_URL = \"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\"\n",
        "HEADERS  = {\"User-Agent\": \"Mozilla/5.0 (compatible; MSBA-Student/1.0)\"}\n",
        "\n",
        "resp = requests.get(WIKI_URL, headers=HEADERS, timeout=20)\n",
        "resp.raise_for_status()\n",
        "html_text = resp.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ1Swg6B82_J"
      },
      "source": [
        "Use Beautiful Soup to parse this string into a tree called `soup`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "e0jpmfwtpaEB"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(html_text, \"html.parser\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFxGW_KIDjnx"
      },
      "source": [
        "To find an HTML tag corresponding to a specific element on a webpage, right-click on it and choose \"Inspect element\". Go to the cities table Wikipedia page and do this now.\n",
        "\n",
        "You should find that the cities table on the Wikipedia page corresponds to the element\n",
        "\n",
        "```\n",
        "<table class=\"wikitable sortable jquery-tablesorter\" style=\"text-align:center\">\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR50aTBZEwov"
      },
      "source": [
        "There are many `<table>` tags on the page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4691d-EGEwc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(soup.find_all(\"table\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1xslM2yE1GI"
      },
      "source": [
        "We can use attributes like `class=` and `style=` to narrow down the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "E0Q0sa46DvTZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(soup.find_all(\"table\",\n",
        "                  attrs={\n",
        "                      \"class\": \"wikitable sortable\",\n",
        "                      \"style\": \"text-align:center\"}\n",
        "                  ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndnRSJJiFFby"
      },
      "source": [
        "At this point, you can manually inspect the tables on the webpage to find that the one we want is the first one (see `[0]` below). We'll store this as `table`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sRBSqVGlYhuT"
      },
      "outputs": [],
      "source": [
        "# AI assistance for this step:\n",
        "# - Keep the instructor's selection; add minimal fallbacks so the cell won't crash if no exact match.\n",
        "try:\n",
        "    table = soup.find_all(\"table\",\n",
        "                          attrs={\"class\": \"wikitable sortable\",\n",
        "                                 \"style\": \"text-align:center\"})[0]  # ← instructor line\n",
        "except IndexError:\n",
        "    # Fallback 1: class-only (common on Wikipedia)\n",
        "    matches = soup.find_all(\"table\", class_=\"wikitable sortable\")\n",
        "    if matches:\n",
        "        table = matches[0]\n",
        "    else:\n",
        "        # Fallback 2: pick the largest table by number of rows\n",
        "        all_tbls = soup.find_all(\"table\")\n",
        "        if not all_tbls:\n",
        "            raise RuntimeError(\"No <table> elements found; check Steps 1–2 and your network.\")\n",
        "        table = max(all_tbls, key=lambda t: len(t.find_all(\"tr\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4AWo3QoYqNY"
      },
      "source": [
        "**Now you will write code to scrape the information in `table` to create a Pandas data frame with one row for each city and columns for: city, state, population (2022 estimate), and 2020 land area (sq mi).** Refer to the Notes/suggestions below as you write your code. A few Hints are provided further down, but try coding first before looking at the hints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfRx2_XlDUqD"
      },
      "source": [
        "Notes/suggestions:\n",
        "\n",
        "- Use as a guide the code from the reading that produced the data frame of Statistics faculty\n",
        "- Inspect the page source as you write your code\n",
        "- You will need to write a loop to get the information for all cities, but you might want to try just scraping the info for New York first\n",
        "- You will need to pull the text from the tag. If `.text` returns text with \"\\n\" at the end, try `.get_text(strip = True)` instead of `.text`\n",
        "- Don't forget to convert to a Pandas Data Frame; it should have 333 rows and 4 columns\n",
        "- The goal of this exercise is just to create the Data Frame. If you were going to use it --- e.g., what is the population density for all cities in CA? --- then you would need to clean the data first (to clean strings and convert to quantitative). (You can use Beautiful Soup to do some of the cleaning for you, but that goes beyond our scope.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "msKiUcOZpSX7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>City</th>\n",
              "      <th>ST</th>\n",
              "      <th>2024estimate</th>\n",
              "      <th>2020census</th>\n",
              "      <th>Change</th>\n",
              "      <th>2020 land area</th>\n",
              "      <th>2020 density</th>\n",
              "      <th>Location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>New York</td>\n",
              "      <td>NY</td>\n",
              "      <td>8,478,072</td>\n",
              "      <td>8,804,190</td>\n",
              "      <td>−3.70%</td>\n",
              "      <td>300.5</td>\n",
              "      <td>778.3</td>\n",
              "      <td>29,298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>CA</td>\n",
              "      <td>3,878,704</td>\n",
              "      <td>3,898,747</td>\n",
              "      <td>−0.51%</td>\n",
              "      <td>469.5</td>\n",
              "      <td>1,216.0</td>\n",
              "      <td>8,304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chicago</td>\n",
              "      <td>IL</td>\n",
              "      <td>2,721,308</td>\n",
              "      <td>2,746,388</td>\n",
              "      <td>−0.91%</td>\n",
              "      <td>227.7</td>\n",
              "      <td>589.7</td>\n",
              "      <td>12,061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>2,390,125</td>\n",
              "      <td>2,304,580</td>\n",
              "      <td>+3.71%</td>\n",
              "      <td>640.4</td>\n",
              "      <td>1,658.6</td>\n",
              "      <td>3,599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Phoenix</td>\n",
              "      <td>AZ</td>\n",
              "      <td>1,673,164</td>\n",
              "      <td>1,608,139</td>\n",
              "      <td>+4.04%</td>\n",
              "      <td>518.0</td>\n",
              "      <td>1,341.6</td>\n",
              "      <td>3,105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          City  ST 2024estimate 2020census  Change 2020 land area  \\\n",
              "0     New York  NY    8,478,072  8,804,190  −3.70%          300.5   \n",
              "1  Los Angeles  CA    3,878,704  3,898,747  −0.51%          469.5   \n",
              "2      Chicago  IL    2,721,308  2,746,388  −0.91%          227.7   \n",
              "3      Houston  TX    2,390,125  2,304,580  +3.71%          640.4   \n",
              "4      Phoenix  AZ    1,673,164  1,608,139  +4.04%          518.0   \n",
              "\n",
              "  2020 density Location  \n",
              "0        778.3   29,298  \n",
              "1      1,216.0    8,304  \n",
              "2        589.7   12,061  \n",
              "3      1,658.6    3,599  \n",
              "4      1,341.6    3,105  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# AI assistance for this step:\n",
        "# - Minimal, safe parse: take header row, iterate data rows, and align with headers.\n",
        "import re\n",
        "\n",
        "def _clean(text: str) -> str:\n",
        "    text = re.sub(r\"\\[[^\\]]*\\]\", \"\", text)      # drop footnote markers like [a], [note 1]\n",
        "    return \" \".join(text.split())\n",
        "\n",
        "# header\n",
        "header_row   = table.find(\"tr\")\n",
        "header_cells = header_row.find_all([\"th\", \"td\"]) if header_row else []\n",
        "headers      = [_clean(h.get_text(strip=True)) for h in header_cells]\n",
        "\n",
        "# rows\n",
        "rows = []\n",
        "for tr in table.find_all(\"tr\")[1:]:\n",
        "    tds = tr.find_all(\"td\")\n",
        "    if not tds:\n",
        "        continue\n",
        "    vals = [_clean(td.get_text(strip=True)) for td in tds]\n",
        "    # align to header length (pad/trim) to avoid shape mismatches\n",
        "    if len(headers):\n",
        "        if len(vals) < len(headers):\n",
        "            vals += [\"\"] * (len(headers) - len(vals))\n",
        "        elif len(vals) > len(headers):\n",
        "            vals = vals[:len(headers)]\n",
        "        rows.append(dict(zip(headers, vals)))\n",
        "    else:\n",
        "        # if no headers, just collect raw cells\n",
        "        rows.append({\"col_\"+str(i): v for i, v in enumerate(vals)})\n",
        "\n",
        "df_cities_bs = pd.DataFrame(rows)\n",
        "df_cities_bs.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s3tH82XZ1X0"
      },
      "source": [
        "Hints:\n",
        "\n",
        "- Each city is a row in the table; find all the `<tr>` tags to find all the cities\n",
        "- Look for the `<td>` tag to see table entries within a row\n",
        "- The rank column is represented by `<th>` tags, rather than `<td>` tags. So within a row, the first (that is, `[0]`) `<td>` tag corresponds to the city name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIW4UgURNdhz"
      },
      "source": [
        "## Aside: Scraping an HTML table with Pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2ufAAMGYenH"
      },
      "source": [
        "The Pandas command `read_html` can be used to scrape information from an HTML table on a webpage.\n",
        "\n",
        "We can call `read_html` on the URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AI assistance for this step:\n",
        "# Fixed blocked (SSL/403), use the HTML we already fetched.\n",
        "\n",
        "from io import StringIO\n",
        "\n",
        "try:\n",
        "    pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\")  \n",
        "except Exception:\n",
        "    pd.read_html(StringIO(html_text))  # same effect, avoids SSL/403 by not re-fetching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQwWgh_cqynb"
      },
      "source": [
        "However, this scrapes all the tables on the webpage, not just the one we want. As with Beautiful Soup, we can narrow the search by specifying the table attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[            City  ST 2024 estimate 2020 census  Change 2020 land area          \\\n",
              "             City  ST 2024 estimate 2020 census  Change            mi2     km2   \n",
              " 0    New York[c]  NY       8478072     8804190  −3.70%          300.5   778.3   \n",
              " 1    Los Angeles  CA       3878704     3898747  −0.51%          469.5  1216.0   \n",
              " 2        Chicago  IL       2721308     2746388  −0.91%          227.7   589.7   \n",
              " 3        Houston  TX       2390125     2304580  +3.71%          640.4  1658.6   \n",
              " 4        Phoenix  AZ       1673164     1608139  +4.04%          518.0  1341.6   \n",
              " ..           ...  ..           ...         ...     ...            ...     ...   \n",
              " 341      Deltona  FL        100513       93692  +7.28%           37.3    96.6   \n",
              " 342  Federal Way  WA        100252      101030  −0.77%           22.3    57.8   \n",
              " 343   San Angelo  TX        100159       99893  +0.27%           59.7   154.6   \n",
              " 344        Tracy  CA        100136       93000  +7.67%           25.9    67.1   \n",
              " 345      Sunrise  FL        100128       97335  +2.87%           16.2    42.0   \n",
              " \n",
              "     2020 density                                      Location  \n",
              "            / mi2  / km2                               Location  \n",
              " 0          29298  11312    40°40′N 73°56′W﻿ / ﻿40.66°N 73.94°W  \n",
              " 1           8304   3206  34°01′N 118°25′W﻿ / ﻿34.02°N 118.41°W  \n",
              " 2          12061   4657    41°50′N 87°41′W﻿ / ﻿41.84°N 87.68°W  \n",
              " 3           3599   1390    29°47′N 95°23′W﻿ / ﻿29.79°N 95.39°W  \n",
              " 4           3105   1199  33°34′N 112°05′W﻿ / ﻿33.57°N 112.09°W  \n",
              " ..           ...    ...                                    ...  \n",
              " 341         2512    970    28°55′N 81°13′W﻿ / ﻿28.91°N 81.21°W  \n",
              " 342         4530   1750  47°19′N 122°20′W﻿ / ﻿47.31°N 122.34°W  \n",
              " 343         1673    646  31°26′N 100°27′W﻿ / ﻿31.44°N 100.45°W  \n",
              " 344         3591   1386  37°44′N 121°27′W﻿ / ﻿37.73°N 121.45°W  \n",
              " 345         6008   2320    26°10′N 80°16′W﻿ / ﻿26.17°N 80.26°W  \n",
              " \n",
              " [346 rows x 10 columns]]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# AI assistance for this step:\n",
        "# - If none are found (Wikipedia sometimes drops the 'style'), minimally relax to class-only.\n",
        "\n",
        "# strict attrs \n",
        "try:\n",
        "    tables_attr = pd.read_html(\n",
        "        StringIO(html_text),\n",
        "        attrs={'class': 'wikitable sortable', 'style': 'text-align:center'}\n",
        "    )\n",
        "except ValueError:\n",
        "    tables_attr = []\n",
        "\n",
        "# minimal relaxation: class-only\n",
        "if not tables_attr:\n",
        "    try:\n",
        "        tables_attr = pd.read_html(\n",
        "            StringIO(html_text),\n",
        "            attrs={'class': 'wikitable sortable'}\n",
        "        )\n",
        "    except ValueError:\n",
        "        tables_attr = []\n",
        "\n",
        "# last resort: parse a single matching <table> fragment so the step still demonstrates the filter idea\n",
        "if not tables_attr:\n",
        "    s5 = BeautifulSoup(html_text, \"html.parser\")\n",
        "    tbl = s5.select_one(\"table.wikitable.sortable\") or s5.select_one(\"table.wikitable\")\n",
        "    tables_attr = pd.read_html(StringIO(str(tbl))) if tbl else []\n",
        "\n",
        "tables_attr  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6P7xCnPrBtS"
      },
      "source": [
        "This still returns 3 tables. As we remarked above, the table that we want is the first one (see `[0]` below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>City</th>\n",
              "      <th>ST</th>\n",
              "      <th>2024 estimate</th>\n",
              "      <th>2020 census</th>\n",
              "      <th>Change</th>\n",
              "      <th colspan=\"2\" halign=\"left\">2020 land area</th>\n",
              "      <th colspan=\"2\" halign=\"left\">2020 density</th>\n",
              "      <th>Location</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>City</th>\n",
              "      <th>ST</th>\n",
              "      <th>2024 estimate</th>\n",
              "      <th>2020 census</th>\n",
              "      <th>Change</th>\n",
              "      <th>mi2</th>\n",
              "      <th>km2</th>\n",
              "      <th>/ mi2</th>\n",
              "      <th>/ km2</th>\n",
              "      <th>Location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>New York[c]</td>\n",
              "      <td>NY</td>\n",
              "      <td>8478072</td>\n",
              "      <td>8804190</td>\n",
              "      <td>−3.70%</td>\n",
              "      <td>300.5</td>\n",
              "      <td>778.3</td>\n",
              "      <td>29298</td>\n",
              "      <td>11312</td>\n",
              "      <td>40°40′N 73°56′W﻿ / ﻿40.66°N 73.94°W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>CA</td>\n",
              "      <td>3878704</td>\n",
              "      <td>3898747</td>\n",
              "      <td>−0.51%</td>\n",
              "      <td>469.5</td>\n",
              "      <td>1216.0</td>\n",
              "      <td>8304</td>\n",
              "      <td>3206</td>\n",
              "      <td>34°01′N 118°25′W﻿ / ﻿34.02°N 118.41°W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chicago</td>\n",
              "      <td>IL</td>\n",
              "      <td>2721308</td>\n",
              "      <td>2746388</td>\n",
              "      <td>−0.91%</td>\n",
              "      <td>227.7</td>\n",
              "      <td>589.7</td>\n",
              "      <td>12061</td>\n",
              "      <td>4657</td>\n",
              "      <td>41°50′N 87°41′W﻿ / ﻿41.84°N 87.68°W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>2390125</td>\n",
              "      <td>2304580</td>\n",
              "      <td>+3.71%</td>\n",
              "      <td>640.4</td>\n",
              "      <td>1658.6</td>\n",
              "      <td>3599</td>\n",
              "      <td>1390</td>\n",
              "      <td>29°47′N 95°23′W﻿ / ﻿29.79°N 95.39°W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Phoenix</td>\n",
              "      <td>AZ</td>\n",
              "      <td>1673164</td>\n",
              "      <td>1608139</td>\n",
              "      <td>+4.04%</td>\n",
              "      <td>518.0</td>\n",
              "      <td>1341.6</td>\n",
              "      <td>3105</td>\n",
              "      <td>1199</td>\n",
              "      <td>33°34′N 112°05′W﻿ / ﻿33.57°N 112.09°W</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          City  ST 2024 estimate 2020 census  Change 2020 land area          \\\n",
              "          City  ST 2024 estimate 2020 census  Change            mi2     km2   \n",
              "0  New York[c]  NY       8478072     8804190  −3.70%          300.5   778.3   \n",
              "1  Los Angeles  CA       3878704     3898747  −0.51%          469.5  1216.0   \n",
              "2      Chicago  IL       2721308     2746388  −0.91%          227.7   589.7   \n",
              "3      Houston  TX       2390125     2304580  +3.71%          640.4  1658.6   \n",
              "4      Phoenix  AZ       1673164     1608139  +4.04%          518.0  1341.6   \n",
              "\n",
              "  2020 density                                      Location  \n",
              "         / mi2  / km2                               Location  \n",
              "0        29298  11312    40°40′N 73°56′W﻿ / ﻿40.66°N 73.94°W  \n",
              "1         8304   3206  34°01′N 118°25′W﻿ / ﻿34.02°N 118.41°W  \n",
              "2        12061   4657    41°50′N 87°41′W﻿ / ﻿41.84°N 87.68°W  \n",
              "3         3599   1390    29°47′N 95°23′W﻿ / ﻿29.79°N 95.39°W  \n",
              "4         3105   1199  33°34′N 112°05′W﻿ / ﻿33.57°N 112.09°W  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# AI assistance for this step:\n",
        "# - Keep the \"first match\" behavior; fall back to the first page-wide table,\n",
        "#   or (if needed) the first <table> fragment to ensure a DataFrame is produced.\n",
        "\n",
        "if tables_attr:\n",
        "    df_cities2 = tables_attr[0]\n",
        "elif tables_all:\n",
        "    df_cities2 = tables_all[0]\n",
        "else:\n",
        "    s53 = BeautifulSoup(html_text, \"html.parser\")\n",
        "    frag = s53.find(\"table\")\n",
        "    df_cities2 = pd.read_html(StringIO(str(frag)))[0] if frag else pd.DataFrame()\n",
        "\n",
        "df_cities2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjeczIIMYeqj"
      },
      "source": [
        "Wait, that seemed much easier than using Beautiful Soup, and it returned a data frame, and we even got for free some formatting like removing the commas from the population! Why didn't we just use `read_html` in the first place? It's true the `read_html` works well when scraping information from an HTML *table*. Unfortunately, you often want to scrape information from a webpage that isn't conveniently stored in an HTML table, in which case `read_html` won't work. (It only searches for `<table>`, `<th>`, `<tr>`, and `<td>` tags, but there are many other HTML tags.) Though Beautiful Soup is not as simple as `read_html`, it is more flexible and thus more widely applicable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctj79YpgX6hw"
      },
      "source": [
        "## Scraping information that is NOT in a `<table>` with Beautiful Soup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK6rJQbuuWwF"
      },
      "source": [
        "The Cal Poly course catalog http://catalog.calpoly.edu/collegesandprograms/collegeofsciencemathematics/statistics/#courseinventory contains a list of courses offered by the Statistics department. **You will scrape this website to obtain a Pandas data frame with one row for each DATA or STAT course and two columns: course name and number (e.g, DATA 301. Introduction to Data Science) and term typically offered (e.g., Term Typically Offered: F, W, SP).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbLLrwxs0eWd"
      },
      "source": [
        "Note: Pandas `read_html` is not help here since the courses are not stored in a `<table>.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QIRewkca0jhz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[                                        Program name   Program type\n",
              " 0                              Actuarial Preparation          Minor\n",
              " 1  Cross Disciplinary Studies Minor in Bioinforma...          Minor\n",
              " 2   Cross Disciplinary Studies Minor in Data Science          Minor\n",
              " 3                                         Statistics  BS, MS, Minor]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.read_html(\"http://catalog.calpoly.edu/collegesandprograms/collegeofsciencemathematics/statistics/#courseinventory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvSrhxS4Se7a"
      },
      "source": [
        "\n",
        "Notes/suggestions:\n",
        "\n",
        "\n",
        "- Inspect the page source as you write your code\n",
        "- The courses are not stored in a `<table>`. How are they stored?\n",
        "- You will need to write a loop to get the information for all courses, but you might want to try just scraping the info for DATA 100 first\n",
        "- What kind of tag is the course name stored in? What is the `class` of the tag?\n",
        "- What kind of tag is the quarter(s) the course is offered stored in? What is the `class` of the tag? Is this the only tag of this type with the class? How will you get the one you want?\n",
        "- You don't have to remove the number of units (e.g., 4 units) from the course name and number, but you can try it if you want\n",
        "- You will need to pull the text from the tag. If `.text` returns text with \"\\n\" at the end, try `get_text(strip = True)` instead of `text`\n",
        "- Don't forget to convert to a Pandas Data Frame; it should have 74 rows and 2 columns\n",
        "- The goal of this exercise is just to create the Data Frame. If you were going to use it then you might need to clean the data first. (You can use Beautiful Soup to do some of the cleaning for you, but that goes beyond our scope.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZbW6xon4vICB"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Course</th>\n",
              "      <th>Term_Typically_Offered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DATA 100. Data Science for All I. 4 units</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DATA 301. Introduction to Data Science. 4 units</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DATA 401. Data Science Process and Ethics. 3 u...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DATA 402. Mathematical Foundations of Data Sci...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DATA 403. Data Science Projects Laboratory. 1 ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Course Term_Typically_Offered\n",
              "0          DATA 100. Data Science for All I. 4 units                       \n",
              "1    DATA 301. Introduction to Data Science. 4 units                       \n",
              "2  DATA 401. Data Science Process and Ethics. 3 u...                       \n",
              "3  DATA 402. Mathematical Foundations of Data Sci...                       \n",
              "4  DATA 403. Data Science Projects Laboratory. 1 ...                       "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# AI assistance for this step:\n",
        "# - Tolerant extraction for \"Term Typically Offered\" (handles variants and optional colon).\n",
        "\n",
        "import re  \n",
        "\n",
        "try:\n",
        "    cat_html = cat_resp.text  \n",
        "except NameError:\n",
        "    CATALOG_URL = globals().get(\n",
        "        \"CATALOG_URL\",\n",
        "        \"http://catalog.calpoly.edu/collegesandprograms/collegeofsciencemathematics/statistics/#courseinventory\"\n",
        "    )\n",
        "    r = requests.get(CATALOG_URL, timeout=20)\n",
        "    r.raise_for_status()\n",
        "    cat_html = r.text\n",
        "\n",
        "soup2 = BeautifulSoup(cat_html, \"html.parser\")\n",
        "\n",
        "records = []\n",
        "for block in soup2.find_all(\"div\", class_=\"courseblock\"):\n",
        "    title_tag = block.find(\"p\", class_=\"courseblocktitle\")\n",
        "    if not title_tag:\n",
        "        continue\n",
        "    course_title = title_tag.get_text(\" \", strip=True)\n",
        "\n",
        "    # patched term extraction: accept \"Term Typically Offered\" or \"Typically Offered\", optional colon\n",
        "    term = \"\"\n",
        "    for p in block.find_all(\"p\", class_=\"noindent courseblockextra\"):\n",
        "        txt = p.get_text(\" \", strip=True)\n",
        "        m = re.search(r\"(?:Term\\s+Typically\\s+Offered|Typically\\s+Offered)\\s*:?\\s*(.*)\", txt, flags=re.I)\n",
        "        if m:\n",
        "            term = m.group(1)\n",
        "            break\n",
        "\n",
        "    records.append({\"Course\": course_title, \"Term_Typically_Offered\": term})\n",
        "\n",
        "df_courses = pd.DataFrame(records)\n",
        "df_courses.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17e8M_OsaHJz"
      },
      "source": [
        "Hints:\n",
        "\n",
        "- Each course is represented by a `<div>` with `class=courseblock`, so you can find all the courses with `soup.find_all(\"div\", {\"class\": \"courseblock\"})`\n",
        "- The course name is in a `<p>` tag with `class=courseblocktitle`, inside a `<strong>` tag. (Though I don't think we need to find the strong tag here.)\n",
        "- The term typically offered is in `<p>` tag with `class=noindent`. However, there are several tags with this class; term typically offered is the first one.\n",
        "- If you want to use Beautiful Soup to remove the course units (e.g., 4 units), find the `<span>` tag within the course name tag and `.extract()` this span tag"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
